"use strict";(self.webpackChunkphysical_ai_robotics_textbook=self.webpackChunkphysical_ai_robotics_textbook||[]).push([[4400],{8439:(e,n,t)=>{t.d(n,{R:()=>a,x:()=>o});var s=t(758);const i={},r=s.createContext(i);function a(e){const n=s.useContext(r);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:a(e.components),s.createElement(r.Provider,{value:n},e.children)}},9039:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>o,default:()=>m,frontMatter:()=>a,metadata:()=>s,toc:()=>c});const s=JSON.parse('{"id":"chapter-4-ai-integration/lesson-6-full-integration","title":"Lesson 6: Full-Stack Integration & Orchestration","description":"Learning Objectives","source":"@site/docs/03-chapter-4-ai-integration/06-lesson-6-full-integration.md","sourceDirName":"03-chapter-4-ai-integration","slug":"/chapter-4-ai-integration/lesson-6-full-integration","permalink":"/physical-ai-robotics-textbook/docs/chapter-4-ai-integration/lesson-6-full-integration","draft":false,"unlisted":false,"editUrl":"https://github.com/devhammad0/physical-ai-robotics-textbook/tree/main/docs/03-chapter-4-ai-integration/06-lesson-6-full-integration.md","tags":[],"version":"current","sidebarPosition":6,"frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Lesson 5: Manipulation, Grasping & Motion Planning","permalink":"/physical-ai-robotics-textbook/docs/chapter-4-ai-integration/lesson-5-manipulation-grasping"},"next":{"title":"Lesson 7: Safety Protocols & Deployment","permalink":"/physical-ai-robotics-textbook/docs/chapter-4-ai-integration/lesson-7-safety"}}');var i=t(6070),r=t(8439);const a={},o="Lesson 6: Full-Stack Integration & Orchestration",l={},c=[{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"System Orchestration Overview",id:"system-orchestration-overview",level:2},{value:"State Machine Design",id:"state-machine-design",level:3},{value:"Orchestrator Implementation",id:"orchestrator-implementation",level:2},{value:"Task Status Monitor",id:"task-status-monitor",level:2},{value:"Launch File for Full Pipeline",id:"launch-file-for-full-pipeline",level:2},{value:"End-to-End Test Scenario",id:"end-to-end-test-scenario",level:2},{value:"Exercises",id:"exercises",level:2},{value:"Exercise L6-1: State Machine Design",id:"exercise-l6-1-state-machine-design",level:3},{value:"Exercise L6-2: End-to-End Integration",id:"exercise-l6-2-end-to-end-integration",level:3},{value:"Real Hardware Considerations",id:"real-hardware-considerations",level:2},{value:"Sim-to-Real Transfer Challenges",id:"sim-to-real-transfer-challenges",level:3},{value:"Domain Randomization",id:"domain-randomization",level:3},{value:"Key Takeaways",id:"key-takeaways",level:2},{value:"Next Steps",id:"next-steps",level:2}];function d(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,r.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"lesson-6-full-stack-integration--orchestration",children:"Lesson 6: Full-Stack Integration & Orchestration"})}),"\n",(0,i.jsx)(n.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,i.jsx)(n.p,{children:"By the end of this lesson, you will:"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsx)(n.li,{children:"Understand system-level orchestration (coordinating all VLA components)"}),"\n",(0,i.jsx)(n.li,{children:"Design state machines for robust autonomous behavior"}),"\n",(0,i.jsx)(n.li,{children:"Implement error handling and recovery strategies"}),"\n",(0,i.jsx)(n.li,{children:"Monitor system health and detect failures"}),"\n",(0,i.jsx)(n.li,{children:"Validate end-to-end performance and latency"}),"\n",(0,i.jsx)(n.li,{children:"Deploy integrated system in Isaac Sim"}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"system-orchestration-overview",children:"System Orchestration Overview"}),"\n",(0,i.jsxs)(n.p,{children:["The orchestrator is the ",(0,i.jsx)(n.strong,{children:"brain"})," that coordinates all components:"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:"\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502           Orchestrator Node (Brain)                  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 \u2022 Listens to voice commands                         \u2502\n\u2502 \u2022 Requests perception (vision)                       \u2502\n\u2502 \u2022 Calls planning (LLM)                              \u2502\n\u2502 \u2022 Manages grasp & motion planning                    \u2502\n\u2502 \u2022 Executes arm motion                                \u2502\n\u2502 \u2022 Monitors execution and handles failures            \u2502\n\u2502 \u2022 Reports status to user                             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2193         \u2193         \u2193         \u2193        \u2193\n      Voice    Vision    Planning  Manipulation Safety\n       Nodes    Nodes     Nodes     Nodes      Nodes\n"})}),"\n",(0,i.jsx)(n.h3,{id:"state-machine-design",children:"State Machine Design"}),"\n",(0,i.jsxs)(n.p,{children:["Robust orchestration requires a ",(0,i.jsx)(n.strong,{children:"state machine"})," that handles all scenarios:"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:"                    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                    \u2502    START    \u2502\n                    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                           \u2502\n                           \u2193\n                    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2192\u2502   IDLE      \u2502\u2190\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n         \u2502          \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518          \u2502\n         \u2502 (done)           \u2502 (voice heard)  \u2502 (reset)\n         \u2502                  \u2193                \u2502\n         \u2502          \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510          \u2502\n         \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2192\u2502 LISTENING   \u2502          \u2502\n         \u2502 \u2502        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518          \u2502\n         \u2502 \u2502 (timeout)     \u2502 (command received)\n         \u2502 \u2502               \u2193                 \u2502\n         \u2502 \u2502        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510          \u2502\n         \u2502 \u2502        \u2502 PERCEIVING  \u2502          \u2502\n         \u2502 \u2502        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518          \u2502\n         \u2502 \u2502               \u2502 (percepts collected)\n         \u2502 \u2502               \u2193                 \u2502\n         \u2502 \u2502        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510          \u2502\n         \u2502 \u2502   \u250c\u2500\u2500\u2500\u2192\u2502  PLANNING   \u2502          \u2502\n         \u2502 \u2502   \u2502    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518          \u2502\n         \u2502 \u2502   \u2502           \u2502 (plan generated)\n         \u2502 \u2502   \u2502replan     \u2193                 \u2502\n         \u2502 \u2502   \u2502    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510          \u2502\n         \u2502 \u2502   \u2514\u2500\u2500\u2500\u2500\u2502 EXECUTING   \u2502          \u2502\n         \u2502 \u2502        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518          \u2502\n         \u2502 \u2502               \u2502 (success)  (failure)\n         \u2502 \u2502               \u2193                 \u2502\n         \u2502 \u2502        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510          \u2502\n         \u2514\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502  OBSERVING  \u2502          \u2502\n         \u2502 \u2502        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518          \u2502\n         \u2502 \u2502               \u2502                 \u2502\n         \u2514\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n"})}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"States"}),":"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"IDLE"}),": Waiting for user command"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"LISTENING"}),": Capturing voice input"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"PERCEIVING"}),": Gathering vision data"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"PLANNING"}),": Calling LLM planner"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"EXECUTING"}),": Moving robot"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"OBSERVING"}),": Checking if execution succeeded"]}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Transitions"}),":"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Command recognized \u2192 PERCEIVING"}),"\n",(0,i.jsx)(n.li,{children:"All percepts ready \u2192 PLANNING"}),"\n",(0,i.jsx)(n.li,{children:"Plan generated \u2192 EXECUTING"}),"\n",(0,i.jsx)(n.li,{children:"Execution complete \u2192 OBSERVING"}),"\n",(0,i.jsx)(n.li,{children:"Plan failed \u2192 back to PLANNING (replan)"}),"\n",(0,i.jsx)(n.li,{children:"User interrupt \u2192 back to IDLE"}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"orchestrator-implementation",children:"Orchestrator Implementation"}),"\n",(0,i.jsxs)(n.p,{children:["File: ",(0,i.jsx)(n.code,{children:"chapter4_integration/src/orchestrator_node.py"})]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'#!/usr/bin/env python3\n\nimport rclpy\nfrom rclpy.node import Node\nfrom rclpy.action import ActionClient\nfrom std_msgs.msg import String\nimport json\nimport uuid\nfrom enum import Enum\nfrom datetime import datetime\nfrom typing import Optional\n\nclass SystemState(Enum):\n    IDLE = "IDLE"\n    LISTENING = "LISTENING"\n    PERCEIVING = "PERCEIVING"\n    PLANNING = "PLANNING"\n    EXECUTING = "EXECUTING"\n    OBSERVING = "OBSERVING"\n    ERROR = "ERROR"\n\nclass OrchestratorNode(Node):\n    def __init__(self):\n        super().__init__(\'orchestrator_node\')\n\n        # Subscribe to all sensor/component topics\n        self.voice_sub = self.create_subscription(\n            String, \'/robot/voice_command\', self.voice_callback, 10\n        )\n        self.detections_sub = self.create_subscription(\n            String, \'/robot/detections\', self.detections_callback, 10\n        )\n        self.plan_sub = self.create_subscription(\n            String, \'/robot/task_plan\', self.plan_callback, 10\n        )\n        self.execution_status_sub = self.create_subscription(\n            String, \'/robot/execution_status\', self.execution_callback, 10\n        )\n\n        # Publish system status\n        self.status_pub = self.create_publisher(\n            String, \'/robot/system_status\', 10\n        )\n\n        # State tracking\n        self.state = SystemState.IDLE\n        self.current_task_id = None\n        self.current_command = None\n        self.current_detections = None\n        self.current_plan = None\n        self.execution_result = None\n        self.retry_count = 0\n        self.max_retries = 3\n\n        # Timers for state transitions\n        self.timer = self.create_timer(0.1, self.state_machine_tick)\n\n        self.get_logger().info(\'Orchestrator Node initialized\')\n\n    def voice_callback(self, msg):\n        """Handle incoming voice command"""\n        self.current_command = msg.data\n        self.current_task_id = str(uuid.uuid4())\n        self.state = SystemState.PERCEIVING\n        self.get_logger().info(f\'Voice command received: "{self.current_command}"\')\n\n    def detections_callback(self, msg):\n        """Store latest perception data"""\n        try:\n            self.current_detections = json.loads(msg.data)\n        except json.JSONDecodeError:\n            self.get_logger().warn(\'Failed to parse detections\')\n\n    def plan_callback(self, msg):\n        """Handle incoming task plan"""\n        try:\n            self.current_plan = json.loads(msg.data)\n            self.state = SystemState.EXECUTING\n            self.get_logger().info(\'Task plan received, transitioning to EXECUTING\')\n        except json.JSONDecodeError:\n            self.state = SystemState.ERROR\n\n    def execution_callback(self, msg):\n        """Monitor execution status"""\n        try:\n            self.execution_result = json.loads(msg.data)\n            if self.execution_result.get(\'is_complete\', False):\n                self.state = SystemState.OBSERVING\n        except json.JSONDecodeError:\n            pass\n\n    def state_machine_tick(self):\n        """Main state machine update"""\n        if self.state == SystemState.IDLE:\n            self._state_idle()\n        elif self.state == SystemState.LISTENING:\n            self._state_listening()\n        elif self.state == SystemState.PERCEIVING:\n            self._state_perceiving()\n        elif self.state == SystemState.PLANNING:\n            self._state_planning()\n        elif self.state == SystemState.EXECUTING:\n            self._state_executing()\n        elif self.state == SystemState.OBSERVING:\n            self._state_observing()\n        elif self.state == SystemState.ERROR:\n            self._state_error()\n\n        self._publish_status()\n\n    def _state_idle(self):\n        """IDLE state: wait for command"""\n        pass  # Wait for voice_callback to trigger\n\n    def _state_listening(self):\n        """LISTENING state: capturing voice"""\n        pass  # Voice node handles this\n\n    def _state_perceiving(self):\n        """PERCEIVING state: gather perception data"""\n        # We have command, now wait for detections\n        if self.current_detections:\n            # Move to planning once we have percepts\n            self.state = SystemState.PLANNING\n            self.get_logger().info(\'Perception data collected, transitioning to PLANNING\')\n\n    def _state_planning(self):\n        """PLANNING state: request LLM plan"""\n        if not self.current_plan:\n            # Publish planning request (LLM planner listens)\n            request = {\n                \'task_id\': self.current_task_id,\n                \'command\': self.current_command,\n                \'detections\': self.current_detections\n            }\n            # In real implementation, would call planning service\n            self.get_logger().info(\'Requesting plan from LLM planner...\')\n\n    def _state_executing(self):\n        """EXECUTING state: execute task"""\n        if self.execution_result and self.execution_result.get(\'is_complete\'):\n            if self.execution_result.get(\'success\'):\n                self.state = SystemState.OBSERVING\n                self.get_logger().info(\'Execution succeeded\')\n            else:\n                # Execution failed, maybe retry\n                if self.retry_count < self.max_retries:\n                    self.retry_count += 1\n                    self.state = SystemState.PLANNING  # Replan\n                    self.get_logger().info(f\'Execution failed, retrying ({self.retry_count}/{self.max_retries})\')\n                else:\n                    self.state = SystemState.ERROR\n                    self.get_logger().error(\'Execution failed after max retries\')\n\n    def _state_observing(self):\n        """OBSERVING state: validate task completion"""\n        # Check if execution succeeded\n        if self.execution_result and self.execution_result.get(\'success\'):\n            self.get_logger().info(\'Task completed successfully!\')\n            self.state = SystemState.IDLE\n            self.retry_count = 0\n        else:\n            self.state = SystemState.ERROR\n\n    def _state_error(self):\n        """ERROR state: handle failures"""\n        self.get_logger().error(f\'System error: {self.execution_result}\')\n        # Reset after error\n        if self.retry_count >= self.max_retries:\n            self.state = SystemState.IDLE\n            self.retry_count = 0\n\n    def _publish_status(self):\n        """Publish current system status"""\n        status = {\n            \'timestamp\': datetime.now().isoformat(),\n            \'state\': self.state.value,\n            \'current_task_id\': self.current_task_id,\n            \'current_command\': self.current_command,\n            \'retry_count\': self.retry_count\n        }\n        msg = String()\n        msg.data = json.dumps(status)\n        self.status_pub.publish(msg)\n\n\ndef main(args=None):\n    rclpy.init(args=args)\n    orchestrator = OrchestratorNode()\n    rclpy.spin(orchestrator)\n    rclpy.shutdown()\n\n\nif __name__ == \'__main__\':\n    main()\n'})}),"\n",(0,i.jsx)(n.h2,{id:"task-status-monitor",children:"Task Status Monitor"}),"\n",(0,i.jsxs)(n.p,{children:["File: ",(0,i.jsx)(n.code,{children:"chapter4_integration/src/task_status_monitor.py"})]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"#!/usr/bin/env python3\n\nimport rclpy\nfrom rclpy.node import Node\nfrom std_msgs.msg import String\nimport json\nfrom datetime import datetime\n\nclass TaskStatusMonitor(Node):\n    \"\"\"Monitor and log task execution progress\"\"\"\n\n    def __init__(self):\n        super().__init__('task_status_monitor')\n\n        # Subscribe to all status topics\n        self.voice_sub = self.create_subscription(\n            String, '/robot/voice_command', self.log_voice, 10\n        )\n        self.detection_sub = self.create_subscription(\n            String, '/robot/detections', self.log_detection, 10\n        )\n        self.plan_sub = self.create_subscription(\n            String, '/robot/task_plan', self.log_plan, 10\n        )\n        self.execution_sub = self.create_subscription(\n            String, '/robot/execution_status', self.log_execution, 10\n        )\n        self.system_status_sub = self.create_subscription(\n            String, '/robot/system_status', self.log_system_status, 10\n        )\n\n        self.execution_trace = []\n\n        self.get_logger().info('Task Status Monitor initialized')\n\n    def log_voice(self, msg):\n        \"\"\"Log voice command\"\"\"\n        self.execution_trace.append({\n            'component': 'voice',\n            'timestamp': datetime.now().isoformat(),\n            'data': msg.data\n        })\n        self.get_logger().info(f'[VOICE] {msg.data}')\n\n    def log_detection(self, msg):\n        \"\"\"Log detected objects\"\"\"\n        try:\n            data = json.loads(msg.data)\n            num_detections = len(data.get('detections', []))\n            self.execution_trace.append({\n                'component': 'vision',\n                'timestamp': datetime.now().isoformat(),\n                'num_detections': num_detections\n            })\n            self.get_logger().info(f'[VISION] Detected {num_detections} objects')\n        except json.JSONDecodeError:\n            pass\n\n    def log_plan(self, msg):\n        \"\"\"Log task plan\"\"\"\n        try:\n            data = json.loads(msg.data)\n            subtasks = data.get('subtasks', [])\n            self.execution_trace.append({\n                'component': 'planning',\n                'timestamp': datetime.now().isoformat(),\n                'num_subtasks': len(subtasks)\n            })\n            self.get_logger().info(f'[PLANNING] Generated {len(subtasks)} subtasks')\n        except json.JSONDecodeError:\n            pass\n\n    def log_execution(self, msg):\n        \"\"\"Log execution progress\"\"\"\n        try:\n            data = json.loads(msg.data)\n            progress = data.get('progress_percent', 0)\n            self.execution_trace.append({\n                'component': 'execution',\n                'timestamp': datetime.now().isoformat(),\n                'progress': progress\n            })\n            self.get_logger().info(f'[EXECUTION] Progress: {progress:.1f}%')\n        except json.JSONDecodeError:\n            pass\n\n    def log_system_status(self, msg):\n        \"\"\"Log system status\"\"\"\n        try:\n            data = json.loads(msg.data)\n            state = data.get('state', 'UNKNOWN')\n            self.get_logger().info(f'[SYSTEM] State: {state}')\n        except json.JSONDecodeError:\n            pass\n\n    def get_execution_trace(self):\n        \"\"\"Retrieve execution trace for debugging\"\"\"\n        return self.execution_trace\n\n\ndef main(args=None):\n    rclpy.init(args=args)\n    monitor = TaskStatusMonitor()\n    rclpy.spin(monitor)\n    rclpy.shutdown()\n\n\nif __name__ == '__main__':\n    main()\n"})}),"\n",(0,i.jsx)(n.h2,{id:"launch-file-for-full-pipeline",children:"Launch File for Full Pipeline"}),"\n",(0,i.jsxs)(n.p,{children:["File: ",(0,i.jsx)(n.code,{children:"chapter4_integration/launch/vla_pipeline.launch.py"})]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"from launch import LaunchDescription\nfrom launch_ros.actions import Node\n\ndef generate_launch_description():\n    \"\"\"Launch all VLA components in correct order\"\"\"\n\n    # 1. Perception nodes (vision)\n    yolo_node = Node(\n        package='chapter4_vision',\n        executable='yolo_detector_node',\n        name='yolo_detector',\n        parameters=[{\n            'model_name': 'yolov8n.pt',\n            'confidence_threshold': 0.5\n        }]\n    )\n\n    segmentation_node = Node(\n        package='chapter4_vision',\n        executable='segmentation_node',\n        name='segmentation'\n    )\n\n    # 2. Voice node\n    voice_node = Node(\n        package='chapter4_voice',\n        executable='whisper_ros2_node',\n        name='whisper'\n    )\n\n    # 3. Planning node (LLM)\n    planning_node = Node(\n        package='chapter4_planning',\n        executable='llm_planner_node',\n        name='llm_planner',\n        parameters=[{\n            'use_openai': True,\n            'model': 'gpt-4'\n        }]\n    )\n\n    # 4. Manipulation nodes (grasp + motion)\n    grasp_planner = Node(\n        package='chapter4_manipulation',\n        executable='grasp_planner_node',\n        name='grasp_planner'\n    )\n\n    motion_planner = Node(\n        package='chapter4_manipulation',\n        executable='motion_planner_node',\n        name='motion_planner'\n    )\n\n    # 5. Orchestrator (coordinates everything)\n    orchestrator = Node(\n        package='chapter4_integration',\n        executable='orchestrator_node',\n        name='orchestrator'\n    )\n\n    # 6. Monitoring\n    status_monitor = Node(\n        package='chapter4_integration',\n        executable='task_status_monitor',\n        name='status_monitor'\n    )\n\n    # 7. Safety (runs independently)\n    safety_validator = Node(\n        package='chapter4_safety',\n        executable='safety_validator_node',\n        name='safety_validator'\n    )\n\n    return LaunchDescription([\n        yolo_node,\n        segmentation_node,\n        voice_node,\n        planning_node,\n        grasp_planner,\n        motion_planner,\n        orchestrator,\n        status_monitor,\n        safety_validator\n    ])\n"})}),"\n",(0,i.jsx)(n.h2,{id:"end-to-end-test-scenario",children:"End-to-End Test Scenario"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"def test_end_to_end_manipulation():\n    \"\"\"Test complete pipeline: voice \u2192 perception \u2192 planning \u2192 manipulation\"\"\"\n\n    # Launch Isaac Sim with scene\n    sim = IsaacSimLauncher()\n    sim.load_scene('scene_2_manipulation_task.yaml')\n\n    # Place objects\n    sim.spawn_object('red_cube', [0.5, 0.3, 0.1])\n    sim.spawn_object('shelf', [0.7, 0.2, 1.2])\n\n    # Launch ROS 2 nodes\n    ros_nodes = launch_vla_pipeline()\n\n    # Simulate voice input\n    voice_publisher = create_publisher('/robot/voice_command', String)\n    voice_publisher.publish('Pick up the red cube and place it on the shelf')\n\n    # Monitor execution\n    execution_trace = []\n    start_time = time.time()\n\n    while time.time() - start_time < 30:\n        # Collect status updates\n        status = get_latest_status()\n        execution_trace.append(status)\n\n        if status['state'] == 'IDLE':\n            # Task completed\n            break\n\n    elapsed_time = time.time() - start_time\n\n    # Validate\n    assert elapsed_time < 15, f'Task took {elapsed_time}s, should be <15s'\n    assert sim.get_object_position('red_cube')[2] > 1.0, 'Cube not on shelf'\n\n    print(f\"\u2713 End-to-end test PASSED ({elapsed_time:.2f}s)\")\n\n    return execution_trace\n"})}),"\n",(0,i.jsx)(n.h2,{id:"exercises",children:"Exercises"}),"\n",(0,i.jsx)(n.h3,{id:"exercise-l6-1-state-machine-design",children:"Exercise L6-1: State Machine Design"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Objective"}),": Design robust state machine for new task"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Steps"}),":"]}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsx)(n.li,{children:'Define task: "Sort colored blocks by color"'}),"\n",(0,i.jsx)(n.li,{children:"Draw state diagram (at least 6 states)"}),"\n",(0,i.jsx)(n.li,{children:"Label all transitions and conditions"}),"\n",(0,i.jsx)(n.li,{children:"Identify failure cases (what if color detection fails?)"}),"\n",(0,i.jsx)(n.li,{children:"Define recovery strategies for each failure"}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Success Criteria"}),":"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"\u2713 State diagram covers happy path"}),"\n",(0,i.jsx)(n.li,{children:"\u2713 All failure modes have recovery"}),"\n",(0,i.jsx)(n.li,{children:"\u2713 No deadlock states"}),"\n",(0,i.jsx)(n.li,{children:"\u2713 Clear transition conditions"}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"exercise-l6-2-end-to-end-integration",children:"Exercise L6-2: End-to-End Integration"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Objective"}),": Run complete VLA pipeline"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Steps"}),":"]}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsx)(n.li,{children:"Launch Isaac Sim with humanoid robot"}),"\n",(0,i.jsxs)(n.li,{children:["Launch all nodes: ",(0,i.jsx)(n.code,{children:"ros2 launch chapter4_integration vla_pipeline.launch.py"})]}),"\n",(0,i.jsx)(n.li,{children:'Give voice command: "Find the red cube"'}),"\n",(0,i.jsxs)(n.li,{children:["Monitor ",(0,i.jsx)(n.code,{children:"/robot/system_status"})," in another terminal"]}),"\n",(0,i.jsxs)(n.li,{children:["Check execution trace: ",(0,i.jsx)(n.code,{children:"rostopic echo /robot/execution_trace"})]}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Success Criteria"}),":"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"\u2713 All nodes launch without errors"}),"\n",(0,i.jsx)(n.li,{children:"\u2713 State machine transitions work"}),"\n",(0,i.jsx)(n.li,{children:"\u2713 Voice command processed"}),"\n",(0,i.jsx)(n.li,{children:"\u2713 Objects detected"}),"\n",(0,i.jsx)(n.li,{children:"\u2713 Plan generated"}),"\n",(0,i.jsx)(n.li,{children:"\u2713 Task completes or fails gracefully"}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"real-hardware-considerations",children:"Real Hardware Considerations"}),"\n",(0,i.jsx)(n.h3,{id:"sim-to-real-transfer-challenges",children:"Sim-to-Real Transfer Challenges"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"In Simulation"}),":"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Perception perfect (camera calibration exact)"}),"\n",(0,i.jsx)(n.li,{children:"Physics deterministic (same grasp \u2192 always succeeds)"}),"\n",(0,i.jsx)(n.li,{children:"No latency (communication instantaneous)"}),"\n",(0,i.jsx)(n.li,{children:"No sensor failures"}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"On Real Hardware"}),":"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Camera calibration 5cm+ error"}),"\n",(0,i.jsx)(n.li,{children:"Object slippage, deformation, unexpected properties"}),"\n",(0,i.jsx)(n.li,{children:"Network latency 50-500ms"}),"\n",(0,i.jsx)(n.li,{children:"Sensors fail intermittently"}),"\n",(0,i.jsx)(n.li,{children:"Humans watching\u2014need to be predictable"}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"domain-randomization",children:"Domain Randomization"}),"\n",(0,i.jsx)(n.p,{children:"To prepare for real world, train on randomized simulations:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"def randomize_simulation():\n    \"\"\"Add noise to simulation for robustness\"\"\"\n    # Random lighting\n    brightness = random.uniform(0.5, 2.0)\n\n    # Random object textures\n    texture = random.choice(['matte', 'glossy', 'reflective'])\n\n    # Random physics\n    friction = random.uniform(0.2, 1.0)\n    density = random.uniform(0.5, 1.5)\n\n    # Random camera noise\n    gaussian_noise = random.normal(0, 0.02)\n\n    return {\n        'lighting': brightness,\n        'texture': texture,\n        'friction': friction,\n        'density': density,\n        'camera_noise': gaussian_noise\n    }\n"})}),"\n",(0,i.jsx)(n.h2,{id:"key-takeaways",children:"Key Takeaways"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Orchestration"})," coordinates all components into unified system"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"State machines"})," provide robust framework for complex behavior"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Error handling"})," and ",(0,i.jsx)(n.strong,{children:"replanning"})," are non-optional"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Monitoring"})," and ",(0,i.jsx)(n.strong,{children:"status reporting"})," help debug failures"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Testing"})," must cover happy path AND failure scenarios"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Sim-to-real"})," requires domain randomization and robustness strategies"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,i.jsxs)(n.p,{children:["In ",(0,i.jsx)(n.strong,{children:"Lesson 7"}),", you'll implement ",(0,i.jsx)(n.strong,{children:"safety protocols"}),":"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Kill switch (emergency stop)"}),"\n",(0,i.jsx)(n.li,{children:"Workspace boundaries"}),"\n",(0,i.jsx)(n.li,{children:"Force limits"}),"\n",(0,i.jsx)(n.li,{children:"Safe recovery states"}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:["These are ",(0,i.jsx)(n.strong,{children:"non-negotiable"})," for real robot deployment!"]}),"\n",(0,i.jsx)(n.p,{children:"See you in Lesson 7! \ud83d\udee1\ufe0f"})]})}function m(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(d,{...e})}):d(e)}}}]);