"use strict";(self.webpackChunkphysical_ai_robotics_textbook=self.webpackChunkphysical_ai_robotics_textbook||[]).push([[8049],{2362:(n,e,s)=>{s.r(e),s.d(e,{assets:()=>l,contentTitle:()=>r,default:()=>m,frontMatter:()=>a,metadata:()=>i,toc:()=>c});const i=JSON.parse('{"id":"chapter-3-autonomous-navigation/capstone-mission","title":"Lesson 8: Capstone - Autonomous Navigation End-to-End","description":"Duration Unlimited | Priority Lessons 1-5 (or 1,3-5 for advanced)","source":"@site/docs/03-chapter-3-autonomous-navigation/08-capstone-mission.md","sourceDirName":"03-chapter-3-autonomous-navigation","slug":"/chapter-3-autonomous-navigation/capstone-mission","permalink":"/physical-ai-robotics-textbook/docs/chapter-3-autonomous-navigation/capstone-mission","draft":false,"unlisted":false,"editUrl":"https://github.com/devhammad0/physical-ai-robotics-textbook/tree/main/docs/03-chapter-3-autonomous-navigation/08-capstone-mission.md","tags":[],"version":"current","sidebarPosition":8,"frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Lesson 7: Multi-Sensor Perception and Fusion","permalink":"/physical-ai-robotics-textbook/docs/chapter-3-autonomous-navigation/multi-sensor-perception-and-fusion"},"next":{"title":"Chapter 4: AI Integration & Vision-Language-Action Pipelines","permalink":"/physical-ai-robotics-textbook/docs/chapter-4-ai-integration/intro"}}');var o=s(6070),t=s(8439);const a={},r="Lesson 8: Capstone - Autonomous Navigation End-to-End",l={},c=[{value:"Learning Outcomes",id:"learning-outcomes",level:2},{value:"Layer 1: Foundation",id:"layer-1-foundation",level:2},{value:"8.1 Complete Autonomous Navigation Pipeline",id:"81-complete-autonomous-navigation-pipeline",level:3},{value:"8.2 Mission Architecture",id:"82-mission-architecture",level:3},{value:"8.3 Multi-Threaded Execution",id:"83-multi-threaded-execution",level:3},{value:"8.4 Diagnostic Recording",id:"84-diagnostic-recording",level:3},{value:"Layer 2: Collaboration (ROS 2 Integration)",id:"layer-2-collaboration-ros-2-integration",level:2},{value:"2.1 Mission Orchestrator Architecture",id:"21-mission-orchestrator-architecture",level:3},{value:"2.2 Complete Navigation System Launch",id:"22-complete-navigation-system-launch",level:3},{value:"2.3 Mission File Format",id:"23-mission-file-format",level:3},{value:"Layer 3: Intelligence (Mission Monitoring &amp; Debugging)",id:"layer-3-intelligence-mission-monitoring--debugging",level:2},{value:"3.1 Real-Time Monitoring",id:"31-real-time-monitoring",level:3},{value:"3.2 Common Failure Modes and Remedies",id:"32-common-failure-modes-and-remedies",level:3},{value:"3.3 Performance Metrics",id:"33-performance-metrics",level:3},{value:"Layer 4: Advanced",id:"layer-4-advanced",level:2},{value:"4.1 Mission Replanning",id:"41-mission-replanning",level:3},{value:"4.2 A/B Testing Different Configurations",id:"42-ab-testing-different-configurations",level:3},{value:"Summary",id:"summary",level:2},{value:"Code Examples",id:"code-examples",level:2},{value:"Example 1: Mission State Machine",id:"example-1-mission-state-machine",level:3},{value:"Example 2: Mission Success Validator",id:"example-2-mission-success-validator",level:3},{value:"Practice Exercise",id:"practice-exercise",level:2},{value:"References",id:"references",level:2},{value:"Next Steps",id:"next-steps",level:2}];function d(n){const e={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,t.R)(),...n.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(e.header,{children:(0,o.jsx)(e.h1,{id:"lesson-8-capstone---autonomous-navigation-end-to-end",children:"Lesson 8: Capstone - Autonomous Navigation End-to-End"})}),"\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"Duration"}),": 3 hours | ",(0,o.jsx)(e.strong,{children:"Level"}),": Unlimited | ",(0,o.jsx)(e.strong,{children:"Priority"}),": P1 | ",(0,o.jsx)(e.strong,{children:"Prerequisite"}),": Lessons 1-5 (or 1,3-5 for advanced)"]}),"\n",(0,o.jsx)(e.h2,{id:"learning-outcomes",children:"Learning Outcomes"}),"\n",(0,o.jsx)(e.p,{children:"By the end of this lesson, you will be able to:"}),"\n",(0,o.jsxs)(e.ol,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Integrate"})," SLAM, Nav2, and sensor fusion into complete autonomous system"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Orchestrate"})," multi-threaded ROS 2 execution with proper synchronization"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Record"})," mission diagnostics for analysis and troubleshooting"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Execute"})," autonomous multi-waypoint missions with dynamic obstacles"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Validate"})," mission success and identify failure modes"]}),"\n"]}),"\n",(0,o.jsx)(e.h2,{id:"layer-1-foundation",children:"Layer 1: Foundation"}),"\n",(0,o.jsx)(e.h3,{id:"81-complete-autonomous-navigation-pipeline",children:"8.1 Complete Autonomous Navigation Pipeline"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{children:"Sensor Input (Gazebo)\n\u251c\u2500 Camera feed \u2192 SLAM system\n\u251c\u2500 LiDAR scan \u2192 Nav2 costmap layer\n\u2514\u2500 IMU data \u2192 Fusion node\n\nProcessing\n\u251c\u2500 SLAM \u2192 pose estimate\n\u251c\u2500 Costmap \u2192 static + dynamic obstacles\n\u251c\u2500 Nav2 planner \u2192 goal path\n\u251c\u2500 Local controller \u2192 velocity commands\n\u2514\u2500 Fusion \u2192 robust position estimate\n\nOutput\n\u2514\u2500 /cmd_vel \u2192 robot motion\n"})}),"\n",(0,o.jsx)(e.h3,{id:"82-mission-architecture",children:"8.2 Mission Architecture"}),"\n",(0,o.jsx)(e.p,{children:"A complete mission orchestrates multiple systems:"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{children:"Mission Orchestrator\n\u2502\n\u251c\u2500 Initialize phase\n\u2502  \u251c\u2500 Start Gazebo simulator\n\u2502  \u251c\u2500 Start SLAM system\n\u2502  \u251c\u2500 Start Nav2 stack\n\u2502  \u251c\u2500 Wait for systems ready\n\u2502  \u2514\u2500 Log mission start\n\u2502\n\u251c\u2500 Execution phase\n\u2502  \u251c\u2500 Send goal pose 1\n\u2502  \u251c\u2500 Monitor navigation progress\n\u2502  \u251c\u2500 Log diagnostics\n\u2502  \u251c\u2500 Detect obstacles / failures\n\u2502  \u251c\u2500 Send goal pose 2, 3, ...\n\u2502  \u2514\u2500 Repeat until all goals reached\n\u2502\n\u2514\u2500 Completion phase\n   \u251c\u2500 Verify all goals reached\n   \u251c\u2500 Record success metrics\n   \u251c\u2500 Save diagnostics log\n   \u2514\u2500 Shutdown systems\n"})}),"\n",(0,o.jsx)(e.h3,{id:"83-multi-threaded-execution",children:"8.3 Multi-Threaded Execution"}),"\n",(0,o.jsx)(e.p,{children:"ROS 2 enables concurrent execution of independent systems:"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{children:"Main thread:           Mission logic\n                       (goal sequencing, monitoring)\n\nSLAM thread:           Camera \u2192 odometry\n                       (continuous processing)\n\nNav2 thread:           Costmap updates \u2192 planning\n                       (continuous processing)\n\nControl thread:        Velocity commands\n                       (continuous at 100+ Hz)\n"})}),"\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"Synchronization"}),": ROS 2 topics and services handle coordination"]}),"\n",(0,o.jsx)(e.h3,{id:"84-diagnostic-recording",children:"8.4 Diagnostic Recording"}),"\n",(0,o.jsx)(e.p,{children:"Record system state for post-mission analysis:"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{children:"Diagnostics collected:\n\u251c\u2500 /tf (frame transformations)\n\u251c\u2500 /odom (odometry estimates)\n\u251c\u2500 /move_base/status (navigation progress)\n\u251c\u2500 /diagnostics (system health)\n\u251c\u2500 /costmap/costmap (obstacle maps)\n\u2514\u2500 Custom mission state\n\nRecorded as rosbag for replay analysis\n"})}),"\n",(0,o.jsx)(e.h2,{id:"layer-2-collaboration-ros-2-integration",children:"Layer 2: Collaboration (ROS 2 Integration)"}),"\n",(0,o.jsx)(e.h3,{id:"21-mission-orchestrator-architecture",children:"2.1 Mission Orchestrator Architecture"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:"# code_examples/autonomous_mission_orchestrator.py\nimport rclpy\nfrom rclpy.executors import MultiThreadedExecutor\nfrom geometry_msgs.msg import PoseStamped\nfrom nav2_msgs.action import NavigateToPose\nfrom rclpy.action import ActionClient\nfrom rclpy.callback_groups import ReentrantCallbackGroup\nimport json\nfrom datetime import datetime\n\nclass MissionOrchestrator(rclpy.Node):\n    def __init__(self, mission_file):\n        super().__init__('mission_orchestrator')\n\n        # Load mission waypoints\n        with open(mission_file) as f:\n            self.mission = json.load(f)\n\n        # Action client for navigation\n        self.nav_client = ActionClient(\n            self, NavigateToPose, 'navigate_to_pose',\n            callback_group=ReentrantCallbackGroup())\n\n        # Result subscribers\n        self.goal_index = 0\n        self.mission_start_time = None\n        self.diagnostics_log = []\n\n        # Timer for periodic updates\n        self.create_timer(1.0, self.monitor_mission)\n\n    def initialize_mission(self):\n        \"\"\"Phase 1: Initialize and verify systems ready\"\"\"\n        self.get_logger().info('Mission initialize phase')\n\n        # Wait for Nav2 to be ready\n        self.nav_client.wait_for_server(timeout_sec=30.0)\n\n        self.get_logger().info('All systems ready. Starting mission.')\n        self.mission_start_time = self.get_clock().now()\n\n        # Send first goal\n        self.send_next_goal()\n\n    def send_next_goal(self):\n        \"\"\"Send next waypoint goal\"\"\"\n        if self.goal_index >= len(self.mission['waypoints']):\n            self.complete_mission()\n            return\n\n        goal = self.mission['waypoints'][self.goal_index]\n\n        # Create Nav2 goal\n        goal_pose = PoseStamped()\n        goal_pose.header.frame_id = 'map'\n        goal_pose.header.stamp = self.get_clock().now().to_msg()\n        goal_pose.pose.position.x = goal['x']\n        goal_pose.pose.position.y = goal['y']\n\n        # Send to Nav2\n        self.nav_client.send_goal_async(\n            NavigateToPose.Goal(pose=goal_pose),\n            feedback_callback=self.feedback_callback)\n\n        self.goal_index += 1\n\n    def feedback_callback(self, feedback):\n        \"\"\"Monitor navigation progress\"\"\"\n        self.diagnostics_log.append({\n            'time': self.get_clock().now().to_msg().sec,\n            'goal_index': self.goal_index,\n            'remaining_distance': feedback.estimated_time_remaining.sec,\n        })\n\n    def monitor_mission(self):\n        \"\"\"Periodic check of mission progress\"\"\"\n        elapsed = (self.get_clock().now() -\n                  self.mission_start_time).nanoseconds / 1e9\n\n        if elapsed > self.mission.get('timeout', 600):\n            self.get_logger().error('Mission timeout!')\n            self.complete_mission()\n\n    def complete_mission(self):\n        \"\"\"Phase 3: Completion and cleanup\"\"\"\n        mission_time = (self.get_clock().now() -\n                       self.mission_start_time).nanoseconds / 1e9\n\n        success = self.goal_index >= len(self.mission['waypoints'])\n\n        self.get_logger().info(\n            f'Mission complete. Success: {success}, '\n            f'Time: {mission_time:.1f}s'\n        )\n\n        # Save diagnostics\n        with open('mission_diagnostics.json', 'w') as f:\n            json.dump(self.diagnostics_log, f)\n\n        rclpy.shutdown()\n"})}),"\n",(0,o.jsx)(e.h3,{id:"22-complete-navigation-system-launch",children:"2.2 Complete Navigation System Launch"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:"# code_examples/complete_navigation_system_launch.py\nimport launch\nfrom launch_ros.actions import Node\nfrom launch_ros.substitutions import FindPackageShare\nimport os\n\ndef generate_launch_description():\n    \"\"\"Launch complete autonomous navigation system\"\"\"\n\n    ld = launch.LaunchDescription()\n\n    # 1. Gazebo simulator with robot\n    ld.add_action(\n        Node(\n            package='gazebo_ros',\n            executable='gazebo',\n            arguments=['gazebo_worlds/capstone_mission_world.world'],\n            output='screen',\n        )\n    )\n\n    # 2. SLAM system (ORB-SLAM3)\n    ld.add_action(\n        Node(\n            package='orb_slam3_ros2',\n            executable='mono_inertial_node',\n            parameters=[{\n                'image_topic': '/camera/image_raw',\n                'output_frame': 'map',\n            }],\n            output='screen',\n        )\n    )\n\n    # 3. Sensor fusion node\n    ld.add_action(\n        Node(\n            package='sensor_fusion',\n            executable='multi_sensor_fusion_node',\n            output='screen',\n        )\n    )\n\n    # 4. Nav2 navigation stack\n    ld.add_action(\n        Node(\n            package='nav2_bringup',\n            executable='bringup_launch.py',\n            arguments=['--use_sim_time', 'true'],\n            output='screen',\n        )\n    )\n\n    # 5. Mission orchestrator\n    ld.add_action(\n        Node(\n            package='mission_orchestration',\n            executable='mission_orchestrator_node',\n            arguments=['capstone_mission.json'],\n            output='screen',\n        )\n    )\n\n    # 6. Recording diagnostics (ROS bag)\n    ld.add_action(\n        Node(\n            package='ros2bag',\n            executable='record',\n            arguments=[\n                '--output', 'mission_recording',\n                '/tf', '/odom', '/move_base/status',\n                '/diagnostics', '/costmap/costmap',\n            ],\n        )\n    )\n\n    return ld\n"})}),"\n",(0,o.jsx)(e.h3,{id:"23-mission-file-format",children:"2.3 Mission File Format"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-json",children:'{\n  "mission_name": "Capstone Autonomous Delivery",\n  "robot_type": "differential_drive",\n  "environment": "warehouse",\n  "timeout": 600,\n  "waypoints": [\n    {"name": "start", "x": 0.0, "y": 0.0, "theta": 0.0},\n    {"name": "shelf_a", "x": 5.0, "y": 0.0, "theta": 0.0},\n    {"name": "shelf_b", "x": 5.0, "y": 5.0, "theta": 1.57},\n    {"name": "checkout", "x": 0.0, "y": 5.0, "theta": 3.14},\n    {"name": "dock", "x": 0.0, "y": 0.0, "theta": 0.0}\n  ],\n  "success_criteria": {\n    "min_mission_success_rate": 0.95,\n    "max_time_per_waypoint": 30,\n    "min_path_distance_efficiency": 0.8\n  }\n}\n'})}),"\n",(0,o.jsx)(e.h2,{id:"layer-3-intelligence-mission-monitoring--debugging",children:"Layer 3: Intelligence (Mission Monitoring & Debugging)"}),"\n",(0,o.jsx)(e.h3,{id:"31-real-time-monitoring",children:"3.1 Real-Time Monitoring"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:"# code_examples/analyze_mission_diagnostics.py\nimport json\nimport numpy as np\nfrom datetime import datetime\n\nclass MissionAnalyzer:\n    def __init__(self, diagnostics_file):\n        with open(diagnostics_file) as f:\n            self.data = json.load(f)\n\n    def analyze(self):\n        \"\"\"Comprehensive mission analysis\"\"\"\n\n        # 1. Success rate\n        successful_goals = sum(1 for d in self.data if d.get('success'))\n        success_rate = successful_goals / len(self.data) * 100\n\n        # 2. Time per waypoint\n        times = [d.get('time_to_goal', 0) for d in self.data]\n        avg_time = np.mean(times)\n        max_time = np.max(times)\n\n        # 3. Failures\n        failures = [d for d in self.data if not d.get('success')]\n\n        print(f'Mission Summary:')\n        print(f'\u251c\u2500 Success rate: {success_rate:.1f}%')\n        print(f'\u251c\u2500 Avg time/waypoint: {avg_time:.1f}s')\n        print(f'\u251c\u2500 Max time: {max_time:.1f}s')\n        print(f'\u2514\u2500 Failures: {len(failures)}')\n\n        # 4. Failure analysis\n        if failures:\n            print(f'\\nFailure Analysis:')\n            for f in failures:\n                print(f'\u251c\u2500 Goal {f[\"goal_index\"]}: {f[\"error_reason\"]}')\n"})}),"\n",(0,o.jsx)(e.h3,{id:"32-common-failure-modes-and-remedies",children:"3.2 Common Failure Modes and Remedies"}),"\n",(0,o.jsxs)(e.table,{children:[(0,o.jsx)(e.thead,{children:(0,o.jsxs)(e.tr,{children:[(0,o.jsx)(e.th,{children:"Failure"}),(0,o.jsx)(e.th,{children:"Cause"}),(0,o.jsx)(e.th,{children:"Remedy"})]})}),(0,o.jsxs)(e.tbody,{children:[(0,o.jsxs)(e.tr,{children:[(0,o.jsx)(e.td,{children:"SLAM diverges"}),(0,o.jsx)(e.td,{children:"Low texture, fast motion"}),(0,o.jsx)(e.td,{children:"Slow down, ensure lighting"})]}),(0,o.jsxs)(e.tr,{children:[(0,o.jsx)(e.td,{children:"Path not found"}),(0,o.jsx)(e.td,{children:"Costmap inflation too large"}),(0,o.jsx)(e.td,{children:"Decrease inflation_radius"})]}),(0,o.jsxs)(e.tr,{children:[(0,o.jsx)(e.td,{children:"Robot oscillates"}),(0,o.jsx)(e.td,{children:"Local planner unstable"}),(0,o.jsx)(e.td,{children:"Tune DWA parameters"})]}),(0,o.jsxs)(e.tr,{children:[(0,o.jsx)(e.td,{children:"Collision"}),(0,o.jsx)(e.td,{children:"Inflation insufficient"}),(0,o.jsx)(e.td,{children:"Increase inflation_radius"})]}),(0,o.jsxs)(e.tr,{children:[(0,o.jsx)(e.td,{children:"Recovery loops"}),(0,o.jsx)(e.td,{children:"Recovery behaviors not working"}),(0,o.jsx)(e.td,{children:"Check behavior tree, tune recovery"})]})]})]}),"\n",(0,o.jsx)(e.h3,{id:"33-performance-metrics",children:"3.3 Performance Metrics"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:"def compute_mission_metrics(mission_data, ground_truth):\n    \"\"\"Compute mission success metrics\"\"\"\n\n    metrics = {\n        'task_completion_rate': 0.0,  # % goals reached\n        'path_length_efficiency': 0.0,  # actual / optimal\n        'collision_count': 0,\n        'recovery_count': 0,\n        'total_time': 0.0,\n        'average_speed': 0.0,\n        'localization_error': 0.0,\n    }\n\n    # Task completion\n    completed = sum(1 for w in mission_data if w['reached'])\n    metrics['task_completion_rate'] = completed / len(mission_data)\n\n    # Path efficiency\n    actual_distance = sum(d['traveled_distance']\n                         for d in mission_data)\n    optimal_distance = compute_optimal_path(mission_data)\n    metrics['path_length_efficiency'] = optimal_distance / actual_distance\n\n    # Collisions and recoveries\n    metrics['collision_count'] = sum(1 for d in mission_data\n                                    if d['collision'])\n    metrics['recovery_count'] = sum(1 for d in mission_data\n                                   if d['recovery_triggered'])\n\n    return metrics\n"})}),"\n",(0,o.jsx)(e.h2,{id:"layer-4-advanced",children:"Layer 4: Advanced"}),"\n",(0,o.jsx)(e.h3,{id:"41-mission-replanning",children:"4.1 Mission Replanning"}),"\n",(0,o.jsx)(e.p,{children:"When initial plan fails, replan online:"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:"class AdaptiveMissionOrchestrator(MissionOrchestrator):\n    def handle_goal_failure(self, goal_index):\n        \"\"\"Replan mission after failure\"\"\"\n\n        # 1. Analyze failure\n        failure_type = self.diagnose_failure()\n\n        # 2. Adapt mission\n        if failure_type == 'costmap_inflation_too_high':\n            self.reduce_inflation()\n        elif failure_type == 'goal_unreachable':\n            self.add_intermediate_waypoint()\n        elif failure_type == 'localization_lost':\n            self.request_localization_recovery()\n\n        # 3. Retry\n        self.send_next_goal()\n"})}),"\n",(0,o.jsx)(e.h3,{id:"42-ab-testing-different-configurations",children:"4.2 A/B Testing Different Configurations"}),"\n",(0,o.jsx)(e.p,{children:"Compare performance across configurations:"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:"# Run mission 3 times with different Nav2 configs\nconfigs = [\n    'nav2_aggressive.yaml',    # Fast but risky\n    'nav2_balanced.yaml',       # Default\n    'nav2_conservative.yaml',   # Slow but safe\n]\n\nfor config in configs:\n    load_nav2_config(config)\n    run_mission(capstone_mission)\n    save_results(config)\n\n# Compare: success rate, time, collisions\ncompare_results(configs)\n"})}),"\n",(0,o.jsx)(e.h2,{id:"summary",children:"Summary"}),"\n",(0,o.jsxs)(e.table,{children:[(0,o.jsx)(e.thead,{children:(0,o.jsxs)(e.tr,{children:[(0,o.jsx)(e.th,{children:"Component"}),(0,o.jsx)(e.th,{children:"Role"})]})}),(0,o.jsxs)(e.tbody,{children:[(0,o.jsxs)(e.tr,{children:[(0,o.jsx)(e.td,{children:(0,o.jsx)(e.strong,{children:"SLAM"})}),(0,o.jsx)(e.td,{children:"Continuous localization and mapping"})]}),(0,o.jsxs)(e.tr,{children:[(0,o.jsx)(e.td,{children:(0,o.jsx)(e.strong,{children:"Nav2"})}),(0,o.jsx)(e.td,{children:"Path planning and obstacle avoidance"})]}),(0,o.jsxs)(e.tr,{children:[(0,o.jsx)(e.td,{children:(0,o.jsx)(e.strong,{children:"Sensor fusion"})}),(0,o.jsx)(e.td,{children:"Robust perception from multiple sensors"})]}),(0,o.jsxs)(e.tr,{children:[(0,o.jsx)(e.td,{children:(0,o.jsx)(e.strong,{children:"Mission orchestrator"})}),(0,o.jsx)(e.td,{children:"High-level goal sequencing"})]}),(0,o.jsxs)(e.tr,{children:[(0,o.jsx)(e.td,{children:(0,o.jsx)(e.strong,{children:"Diagnostics"})}),(0,o.jsx)(e.td,{children:"Record and analyze performance"})]})]})]}),"\n",(0,o.jsx)(e.h2,{id:"code-examples",children:"Code Examples"}),"\n",(0,o.jsx)(e.h3,{id:"example-1-mission-state-machine",children:"Example 1: Mission State Machine"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:"# code_examples/mission_state_machine.py\nfrom enum import Enum\nimport rclpy\n\nclass MissionState(Enum):\n    IDLE = 0\n    INITIALIZING = 1\n    EXECUTING = 2\n    RECOVERING = 3\n    COMPLETE = 4\n\nclass MissionStateMachine:\n    def __init__(self):\n        self.state = MissionState.IDLE\n\n    def transition(self, event):\n        \"\"\"Handle state transitions\"\"\"\n\n        transitions = {\n            MissionState.IDLE: {\n                'initialize': MissionState.INITIALIZING,\n            },\n            MissionState.INITIALIZING: {\n                'ready': MissionState.EXECUTING,\n                'failed': MissionState.IDLE,\n            },\n            MissionState.EXECUTING: {\n                'goal_reached': MissionState.EXECUTING,\n                'mission_complete': MissionState.COMPLETE,\n                'failure': MissionState.RECOVERING,\n            },\n            MissionState.RECOVERING: {\n                'recovered': MissionState.EXECUTING,\n                'failed': MissionState.IDLE,\n            },\n        }\n\n        next_state = transitions[self.state].get(event)\n        if next_state:\n            self.state = next_state\n            return True\n        return False\n"})}),"\n",(0,o.jsx)(e.h3,{id:"example-2-mission-success-validator",children:"Example 2: Mission Success Validator"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:"# code_examples/validate_mission_success.py\nclass MissionValidator:\n    def __init__(self, mission_spec):\n        self.spec = mission_spec\n\n    def validate_completion(self, mission_results):\n        \"\"\"Check if mission meets success criteria\"\"\"\n\n        criteria = self.spec['success_criteria']\n\n        # Check task completion rate\n        completion_rate = (mission_results['goals_reached'] /\n                         len(self.spec['waypoints']))\n        if completion_rate < criteria['min_mission_success_rate']:\n            return False, f'Completion rate {completion_rate:.1%}'\n\n        # Check per-waypoint timing\n        for result in mission_results['waypoints']:\n            if result['time'] > criteria['max_time_per_waypoint']:\n                return False, f'Waypoint {result[\"id\"]} timeout'\n\n        # Check path efficiency\n        efficiency = (mission_results['optimal_distance'] /\n                     mission_results['actual_distance'])\n        if efficiency < criteria['min_path_distance_efficiency']:\n            return False, f'Path efficiency {efficiency:.1%}'\n\n        return True, 'Mission successful'\n"})}),"\n",(0,o.jsx)(e.h2,{id:"practice-exercise",children:"Practice Exercise"}),"\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"Objective"}),": Design, execute, and validate a complete autonomous mission"]}),"\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"Steps"}),":"]}),"\n",(0,o.jsxs)(e.ol,{children:["\n",(0,o.jsx)(e.li,{children:"Design mission with 5+ waypoints in Gazebo"}),"\n",(0,o.jsx)(e.li,{children:"Write mission file (JSON) with waypoint coordinates"}),"\n",(0,o.jsx)(e.li,{children:"Launch complete navigation system"}),"\n",(0,o.jsx)(e.li,{children:"Monitor mission progress in real-time"}),"\n",(0,o.jsxs)(e.li,{children:["Analyze mission diagnostics:","\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"Success rate (target: 100%)"}),"\n",(0,o.jsx)(e.li,{children:"Average time per waypoint (target: <10s)"}),"\n",(0,o.jsx)(e.li,{children:"Collision count (target: 0)"}),"\n",(0,o.jsx)(e.li,{children:"Path efficiency (target: >80%)"}),"\n"]}),"\n"]}),"\n",(0,o.jsx)(e.li,{children:"Debug failures if any"}),"\n"]}),"\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"Success criteria"}),":"]}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"Mission completes successfully"}),"\n",(0,o.jsx)(e.li,{children:"All waypoints reached"}),"\n",(0,o.jsx)(e.li,{children:"No collisions"}),"\n",(0,o.jsx)(e.li,{children:"Path efficiency >80%"}),"\n",(0,o.jsx)(e.li,{children:"Complete diagnostics log saved"}),"\n"]}),"\n",(0,o.jsx)(e.h2,{id:"references",children:"References"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Autonomous Systems Architecture"}),": ",(0,o.jsx)(e.a,{href:"https://www.ros.org/",children:"System Integration Guide"})]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Mission Planning"}),": ",(0,o.jsx)(e.a,{href:"https://arxiv.org/abs/1802.06066",children:"Task and Motion Planning Survey"})]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"ROS 2 Best Practices"}),": ",(0,o.jsx)(e.a,{href:"https://design.ros2.org/",children:"ROS 2 Design Guidelines"})]}),"\n"]}),"\n",(0,o.jsx)(e.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,o.jsx)(e.p,{children:"You've completed Chapter 3! Congratulations on mastering autonomous navigation."}),"\n",(0,o.jsx)(e.p,{children:(0,o.jsx)(e.strong,{children:"What's next?"})}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Chapter 4"}),": AI and Large Language Models for robotics"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Advanced topics"}),": Real-world deployment, sim-to-real transfer, multi-robot coordination"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Research"}),": Contribute to open-source ROS 2 navigation projects"]}),"\n"]}),"\n",(0,o.jsx)(e.hr,{}),"\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"Capstone Summary"}),": The capstone integrates SLAM, Nav2, sensor fusion, and mission orchestration into a complete autonomous system. Successfully executing complex multi-waypoint missions with dynamic obstacles demonstrates mastery of all Chapter 3 concepts."]}),"\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"Congratulations!"})," You're now equipped to design, implement, and deploy autonomous navigation systems in simulation and real-world environments."]}),"\n",(0,o.jsx)(e.hr,{}),"\n",(0,o.jsx)(e.p,{children:(0,o.jsx)(e.strong,{children:"Chapter 3 Complete"})}),"\n",(0,o.jsx)(e.p,{children:"You've learned:\n\u2705 SLAM fundamentals and ORB-SLAM3 implementation\n\u2705 Isaac Sim photorealistic simulation\n\u2705 Nav2 path planning with global and local control\n\u2705 Obstacle avoidance and dynamic environments\n\u2705 Humanoid-specific navigation constraints\n\u2705 Multi-sensor perception and fusion\n\u2705 End-to-end mission orchestration"}),"\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"Total duration"}),": 18-20 hours\n",(0,o.jsx)(e.strong,{children:"Lessons"}),": 8 (+ 1 capstone)\n",(0,o.jsx)(e.strong,{children:"Code examples"}),": 30+\n",(0,o.jsx)(e.strong,{children:"Simulation environments"}),": Gazebo + Isaac Sim\n",(0,o.jsx)(e.strong,{children:"Robot platforms"}),": Differential drive + Humanoid"]}),"\n",(0,o.jsx)(e.p,{children:"Ready for Chapter 4? Let's add intelligence with LLMs and AI!"})]})}function m(n={}){const{wrapper:e}={...(0,t.R)(),...n.components};return e?(0,o.jsx)(e,{...n,children:(0,o.jsx)(d,{...n})}):d(n)}},8439:(n,e,s)=>{s.d(e,{R:()=>a,x:()=>r});var i=s(758);const o={},t=i.createContext(o);function a(n){const e=i.useContext(t);return i.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function r(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(o):n.components||o:a(n.components),i.createElement(t.Provider,{value:e},n.children)}}}]);